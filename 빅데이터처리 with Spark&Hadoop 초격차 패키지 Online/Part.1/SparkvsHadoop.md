Spark vs MapReduce : Performance
Hadoop MapReduce는 디스크에서 작업을 수행하기 때문에 상대적으로 느리고 데이터에서 거의 실시간 분석을 제공할 수 없습니다.
반면 Spark는 데이터를 디스크 I/O가 아닌 메모리 내로 변환하여 처리 시간을 단축하도록 설계되었습니다. Spark는 실제로 메모리 내에서 100배, 디스크에서 10배 더 빠르다. MapReduce와 달리 실시간 처리를 처리할 수 있습니다.
Hadoop MapReduce는 모든 Map 또는 Reduce 작업 후에 데이터를 디스크에 다시 저장해야 합니다.Spark가 효과적으로 작동하려면 많은 RAM이 필요합니다. Spark는 프로세스를 메모리에 저장하고 다른 지침이 제공되지 않으면 메모리에 유지합니다. Spark를 다른 리소스 요구 서비스와 함께 사용하면 성능이 현저히 저하될 수 있습니다. 또한 데이터 소스가 너무 커서 메모리에 완전히 들어갈 수 없는 경우 Spark의 성능이 저하됩니다.MapReduce는 데이터 캐싱을 제공하지 않지만 다른 서비스는 완료되는 즉시 작업을 종료하므로 성능 저하가 거의 없이 지원할 수 있습니다.MapReduce와 Spark는 모두 성능 면에서 이점이 있습니다. Spark는 보유한 메모리 공간의 양으로 데이터를 수용할 수 있거나 전용 클러스터가 있는 경우 빅 데이터 요구 사항에 가장 적합한 선택입니다. 반면에 MapReduce는 메모리에 깔끔하게 들어맞지 않는 대용량 데이터가 있고 다른 서비스와 조정하기 위한 데이터 프레임워크가 필요한 경우 더 나은 솔루션입니다.
 
Spark vs MapReduce : Cost
Hadoop은 오픈 소스 소프트웨어이기 때문에 더 저렴한 비용으로 실행되며 상대적으로 저렴한 상품인 디스크에 더 많은 메모리가 필요합니다. Spark에는 더 많은 RAM이 필요하므로 Spark 클러스터를 설정하는 데 비용이 더 많이 들 수 있습니다. 
 
최적의 성능을 위해서는 데이터가 메모리에 맞아야 하기 때문에 Spark 클러스터의 메모리는 최소한 처리해야 하는 데이터의 양만큼 커야 합니다. 매우 많은 양의 데이터를 처리해야 하는 경우 하드 디스크 공간이 메모리 공간보다 훨씬 저렴하기 때문에 Hadoop이 더 저렴한 옵션이 될 수 있습니다.반면 스파크와 맵리듀스의 성능을 고려할 때 스파크가 더 저렴한 옵션이 될 수 있습니다. Spark는 특히 컴퓨팅 성능이 사용량에 따라 지불되는 클라우드에서 동일한 작업을 훨씬 더 빠르게 수행하기 위해 더 적은 하드웨어가 필요합니다.
 
Fault Tolerance
MapReduce는 엄밀히 말하면 영구 저장소를 사용하는 디스크 기반입니다. 둘 다 어느 정도의 처리 실패를 제공하지만 Spark의 내결함성은 주로 RDD(복원적인 분산 데이터 집합) 작업을 기반으로 합니다. RDD는 Apache Spark의 빌딩 블록입니다. Hadoop은 여러 노드에 걸쳐 데이터를 복제하도록 설계되었기 때문에 자연스럽게 내결함성이 있습니다.
MapReduce는 RAM 대신 하드 드라이브를 사용하기 때문에 Spark보다 장애 후 복구에 더 적합합니다. Spark가 데이터 처리 활동 중 충돌 후 다시 온라인 상태가 되면 처음부터 다시 시작해야 합니다. 이 프로세스에는 더 많은 시간이 필요합니다.MapReduce가 작업을 수행하는 동안 실패하면 다시 시작할 때 중단된 위치에서 다시 시작됩니다. 맵리듀스는 하드디스크를 기반으로 하기 때문에 작업 중간에 실패해도 제자리를 유지할 수 있습니다.Spark와 Hadoop MapReduce는 모두 높은 내결함성을 갖지만 Hadoop MapReduce는 약간 더 관대합니다.
 
 
 
MapReduce를 사용하면 좋을 때
 
거대한 데이터 세트의 선형 처리. Linear processing of huge data sets.
Hadoop MapReduce를 사용하면 방대한 양의 데이터를 병렬로 처리할 수 있습니다. 큰 청크를 더 작은 청크로 나누어 다른 데이터 노드에서 별도로 처리하고 여러 노드에서 결과를 자동으로 수집하여 단일 결과를 반환합니다. 결과 데이터 세트가 사용 가능한 RAM보다 큰 경우 Hadoop MapReduce가 Spark를 능가할 수 있습니다.
 
즉각적으로 결과가 필요하지 않는 경우 경제적인 솔루션이다. 
Hadoop 팀은 처리 속도가 중요하지 않은 경우 MapReduce를 좋은 솔루션으로 간주합니다. 예를 들어 야간에 데이터 처리가 가능하다면 Hadoop MapReduce 사용을 고려하는 것이 좋습니다.
 
 
Spark를 사용하면 좋을 때
 
빠른 데이터 처리. 
인메모리 프로세싱은 Spark를 Hadoop MapReduce보다 빠르게 만듭니다. RAM의 데이터는 최대 100배, 스토리지의 데이터는 최대 10배입니다.
반복 처리. 
작업이 데이터를 계속해서 처리하는 것이라면 Spark는 Hadoop MapReduce를 물리칩니다. Spark의 RDD(Resilient Distributed Datasets)는 메모리에서 여러 맵 작업을 가능하게 하는 반면 Hadoop MapReduce는 중간 결과를 디스크에 기록해야 합니다.
 
Near real-time processing. 
비즈니스에 즉각적인 통찰력이 필요한 경우 Spark 및 메모리 내 처리를 선택해야 합니다.
그래프 처리. 
Spark의 계산 모델은 그래프 처리에서 일반적인 반복 계산에 적합합니다. 그리고 Apache Spark에는 그래프 계산을 위한 API인 GraphX가 있습니다.
기계 학습. 
Spark에는 내장된 기계 학습 라이브러리인 MLlib가 있으며, MLlib에는 메모리에서도 실행되는 즉시 사용 가능한 알고리즘이 있습니다.
 
Joining datasets.
Spark는 속도 때문에 모든 조합을 더 빠르게 생성할 수 있지만 많은 shuffling과 sorting이 필요한 매우 큰 데이터 세트를 joining해야 하는 경우 Hadoop이 더 나을 수 있습니다.
출처: https://sunrise-min.tistory.com/entry/MapReduce-vs-Spark-맵리듀스와-스파크의-차이점 [내가 보기 위한 기록:티스토리]
